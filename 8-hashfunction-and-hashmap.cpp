#include <iostream>
#include <random>
#include <string>
#include <unordered_map>
#include <unordered_set>
#include <vector>

using std::cout;
using std::string;
using std::unordered_map;
using std::unordered_set;
using std::vector;

// 与哈希函数有关的结构

// = 哈希函数
//      out = f(in)
//  1) 输入域无穷, 输出域相对有限
//      例如, md5: 输出范围 0~2^64-1, SHA1: 输出范围 0~2^128-1
//  2) 相同输入相同输出
//  3) 不同输入可能有相同输出 (哈希碰撞)
//  4) 离散性和均匀性
//      离散性: 非常相似的输入给出的输出都是完全不同的
//      均匀性: 输出是均匀地, 即连续有规律的输入, 得到的输出是均匀分布在整个输出域的
// 目前流行的哈希函数有上百种, 但是这几个特性都是所有的哈希函数需要维护的

// = 哈希表
// 在哈希函数的基础上, 可以继续进行操作从而得到哈希表
// in set不管是否均匀, 经过哈希函数之后, 得到的out set都是均匀的, 再次基础上进行取模m操作, 得到的结果也一定是均匀分布的
//     in set               out set                  m set
//  ,----------,         ,----------,            ,----------,
//  |   in 1   |         |   out 1  |            |    m 0   | ---> Linked List 0
//  |   in 2   |    f    |   out 2  |     % m    |    m 1   | ---> Linked List 1
//  |   in 3   | ------> |   out 3  | ---------> |    m 2   | ---> Linked List 2
//  |   in 4   |         |   out 4  |            |    ...   |           ...
//  |   in 5   |         |   out 5  |            |    m-1   | ---> Linked List m-1
//  '----------'         '----------'            '----------'
// m set可能会出现碰撞, 因此m set本身作为一个数组, 其中每个元素都是一个指向链表的指针
// = 最终的就得到了哈希表和哈希集合, 即m set
// 整个过程中最重要的其实就是哈希函数的离散性和均匀性, 因此很多哈希函数的题要的都是离散性和均匀性

// = 接下来看一下哈希表的时间复杂度
// 假设一开始m = 17, 插入了N个数据, 那么最后平均m set中每个链表的长度都是 N/17
// 此时进行增删改查的时间复杂度就是: 计算哈希值O(1) + 取模O(1) + 遍历链表O(N)
// 那么这样一来哈希表时间复杂度就是O(N)了, 虽然N的常数很小, 但还是不好
// 因此在原先的哈希表的基础上定义扩容逻辑, 即定义一个常数K, 如果发现m set中的某个链表长度超过K了
// 那么m set数组扩容一倍, 即未来取余取 34, 这样一来原先m set中所有链接在链表上的元素需要重新计算插入新的m set
// 计算一下插入的时间复杂度, 每个链表长度现在是K, 那么查询操作时间复杂度就是 计算哈希值O(1) + 取模O(1) + 遍历链表O(K)
// 因此在规定了链表最大长度为K之后, 时间复杂度就是O(1) (其实是O(K), 但是因为K一般都比较小)
// 但是还需要计算一下需要扩容多少次, 一个有N个值插入, 假设最坏的情况, 从m=2开始依次扩容
// 那么最终经历的扩容次数就是 O(logN), 而每次扩容的时候里面的数据全都需要重新计算哈希值, 重新挂到m set的链表中
// 因此插入N个数据的总代价就是 O(NlogN), 而单次插入数据的代价就是O(logN)
// = 所以经过这样的改进, 哈希表的插入操作代价就是 O(logN), 查询操作就是 O(1)

// = 此外还有对哈希表的改进
// Java代码是完全托管给JVM虚拟机运行的, 因此可以实现离线扩容技术, 即在用户处理别的事情的时候, JVM去额外申请一个哈希表进行扩容
// 然后将扩容时候的操作均摊到每次用户代码空闲的时候, 这样等到用户真正需要扩容的时候就不需要重复了
// 因此哈希表理论上的插入N个数据时间复杂度是O(logN), 但是在使用的时候可以视为O(1)
// 不过离线扩容技术对于C++这类静态语言就没办法了, 因此C++的扩容完全是由用户的代码却决定的
// 此外还有优化操作, 就是m set不挂链表, 挂一个二叉树或者红黑树, 从而进一步加速查询

template<typename Key>
class RandomPool {
	// 设计RandomPool结构
	// 【题目】设计一种结构，在该结构中有如下三个功能:
	//      insert(key):将某个key加入到该结构，做到不重复加入
	//      delete(key):将原本在结构中的某个key移除
	//      getRandom():等概率随机返回结构中的任何一个key。
	// 【要求】Insert、delete和getRandom方法的时间复杂度都是O(1)
private:
	// 这个题千万别想着手动实现一个哈希表, 那不然做不出来了. 核心就是直接利用哈希表
	size_t size = 0;
	static std::random_device seed;
	static std::ranlux48 engin;
	unordered_map<Key, int> keyIndexMap{};
	unordered_map<int, Key> indexKeyMap{};

public:
	RandomPool() { engin = std::ranlux48(seed()); }
	RandomPool(vector<Key> &vec) {
		engin = std::ranlux48(seed());
		for (int i = 0; i < vec.size(); i++)
			keyIndexMap.insert(std::make_pair(vec[i], i)), indexKeyMap.insert(std::make_pair(i, vec[i]));
		size = vec.size();
	}

	void insertKey(Key key) {
		keyIndexMap.insert(std::make_pair(key, size));
		indexKeyMap.insert(std::make_pair(size, key));
		size++;
	}

	void deleteKey(Key key) {
		if (!keyIndexMap.contains(key))
			return;
		int deleteIndex = keyIndexMap[key];
		int lastIndex = --size;
		Key lastKey = indexKeyMap[lastIndex];
		keyIndexMap[lastKey] = deleteIndex;
		indexKeyMap[deleteIndex] = lastKey;
		keyIndexMap.erase(key);
		indexKeyMap.erase(lastIndex);
		size--;
	}

	Key getRandom() {
		if (size == 0)
			return nullptr;
		std::uniform_int_distribution<> dist(0, size);
		return indexKeyMap[dist(engin)];
	}
};


// = 布隆过滤器
// 在哈希函数的基础上, 就可以实现布隆过滤器
// 布隆过滤器用于实现大数据量下的黑名单问题, 例如: url黑名单, 爬虫重复爬取等问题
// 注意, 布隆过滤器仅支持增加和查询两种操作, 不支持删除操作
// 假设现在有100亿个黑名单URL, 每个URL使用64个字节存储, 如果使用哈希表存储则需要6400亿字节, 320G内存才能处理
// 至少是需要一个服务器集群才能完成这个任务
// 如何减少内存使用, 使得能够在32G内存的服务器上完成100亿个URL的黑名单?
// 布隆过滤器允许一定程度的误报率. 对于误报, 存在两类误报:
//      1. 黑名单中的项目误报为白名单
//      2. 白名单中的项目误报为黑名单
// 布隆过滤器只会存在第二种误报

// = 布隆过滤器原理就是通过哈希函数 + 位图减少内存使用
// 首先有K个哈希函数, 位图中有M个位.
// 对于添加黑名单操作, 每来一个URL根据K个哈希函数计算得到K个值, 对M取余得到K个位置, 而后将位图中这K个位置的值设置为1, 即添加黑名单
// 对于查询黑名单操作, 每来一个URL根据K个哈希函数计算得到K个值, 对M取余得到K个位置, 而后查询位图中这K个位置的值是否都为1, 如果是则是黑名单中的URL

// 对于布隆过滤器, 在实现的时候需要考虑两个因素, 第一个是样本量N, 第二个是失误率P
// 根据这两个值, 就可以确定需要多少个哈希函数和位图的大小(按照位计算)
// 位图大小 M = - (n * lnP) / ln2^2
// 哈希函数个数 K = ln2 * m/n ~= 0.7 * m/n, 向上取整
// 所以对于上面的问题, 样本量N=100亿, 失误率P=万分之一, 计算得出需要13个哈希函数, 位图占用28G内存
// 如果给定位图大小的话, 例如现在有32G可以用, 那么真实失误率就为
// P真 = (1 - e ^ (- N*K/M真)) ^ K真
// 代入32G计算得到的真实失误率为十万分之六, 可见平均十万个URL中会有6个URL被误报为黑名单


// = 一致性哈希
// 一致性哈希的背景: 分布式系统的扩容和负载均衡问题
// 大多数网站背后肯定不是只有一台服务器提供服务，因为单机的并发量和数据量都是有限的，所以都会用多台服务器构成集群来对外提供服务。
// 服务器可以分为逻辑服务器和数据服务器,
//      逻辑服务器负责业务逻辑的实现, 对外暴露调用接口
//      数据服务器负责向逻辑服务器屏蔽底层数据细节, 使得逻辑服务器可以按照统一的接口获得数据
// 那么就存在问题了, 多个数据集服务器组成的数据服务器集群中, 如何分配数据?
// 首先最好想到的方案就是通过每个机器唯一的标识符, 例如MAC地址或者内网的IP地址取哈希, 得到服务器的一个身份
// 而后每来一个数据 (一般都是通过key查value), 对该key计算一次哈希, 然后对数据服务器的数量取余, 就能得到这个key对应的value保存在哪个服务器中
// 这样做类似于上面提到的哈希表的实现, 只不过现在m set中每个元素都是数据服务器了
// = 那么问题来了, 根据前面介绍的哈希表的实现, 如果需要新增加一个数据服务器的话, 那么就需要把所有的数据充分取出来, 计算哈希值
// = 然后重新分配到所有的服务器中, 这样做代价就很大, 因为所有的数据服务器需要离线更新数据, 此外删除一个服务器也会面临同样的问题
// = 如何去实现高效的扩展数据服务器集群?
// = 更通用的概念就是, 如何在一个分布式系统中实现动态地扩容和删除? 一致性哈希就是解决这个问题的
// 回到上面的场景, 我们现在查询一个值, 这个值哈希计算出来的范围(假设是md5计算的哈希)就是0~2^64-1
// 我们对这个值取余(假设三台服务器), 使得最终的范围落在了0, 1, 2这三个服务器上
// 如果我们能高效利用哈希计算出来的范围, 例如, 服务器0负责范围是0~2^64*(1/3)这个范围的数据, 服务器1负责2^64/3~2^64*(2/3)这个范围的数据, 服务器2负责2^64*(2/3)~2^64-1这个范围的数据
// 未来如何需要增加一台服务器的话, 那么四个服务器平分0~2^64-1这个范围的数据就可以解决这个问题
// 所以查询数据的过程中, 我们首先要做的第一步就是把哈希函数的值域头尾连接得到一个环. 即哈希环
// 例如现在三个服务器通过mac地址计算哈希之后得到的值为: 5亿, 10亿, 15亿 (假设哈希函数计算得到的值域为15亿)
// 而后每次针对要获得值的key计算key的哈希, 根据这个哈希顺时针找到数据所属的服务器. 例如现在计算得到的值是2亿, 那么这个数据就在哈希值为5亿的服务器上
// 再来一个数据, 计算得到的哈希值为13亿, 那么这个数据就在哈希为15亿的服务器上.
// 未来新加了一个服务器, 假设新增加的服务器的计算得到的哈希是13亿, 那么就把10-13亿哈希的数据从15亿的服务器上拷贝到新服务器
// 未来新服务器负责10-13亿哈希值的数据, 15亿哈希的服务器负责13-15亿的数据即可.
// = 所以通过这种方式就可以动态地实现扩容和删除
// = 这种方式存在两个问题
// = 第一个问题就是只有服务器足够的多, 才能够平分整个哈希区间, 否则就会出现不均衡的问题
// 例如服务器A的哈希值是13亿, 服务器B的哈希值是15亿(假设哈希函数值域为0~15亿), 那么第一台服务器就要承受13亿的流量, 第二台服务器只承受2亿的流量
// 一直直到服务器数量多起来, 才能够平分整个流量.
// = 第二个问题就是服务器的负载控制问题, 假设我现在服务器A的性能很强, 能处理10亿的流量, 服务器B一般, 能承受4亿的流量, 而服务器C很弱, 只能承受1亿的流量, 如何控制负载?
// 如果是原始的哈希, 那么很有可能A计算的哈希是3亿, B计算的哈希是10亿, C计算的哈希是15亿, 这样就浪费了服务器A的性能
// = 所以针对这两个问题, 就有虚拟节点的方式来解决.
// 虚拟节点指为一个服务器生成多个哈希值, 例如一个服务器通过1000个身份字符串生成了1000个哈希
// 然后第二个服务器也生成了1000个哈希
// 2000个节点能够较好的均分哈希环, 所以未来就不是服务器自己去抢节点了, 而是通过虚拟节点去分配哈希的值域
// 这样做就解决了一开始均衡问题. 同时如果要控制负载的话, 那么就给服务器A 2000个节点, 服务器B500个节点, 这样一来就可以实现负载的动态分配


int main(int argc, char *argv[]) {
	return 0;
}